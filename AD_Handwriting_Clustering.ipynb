{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750d605f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 1. Setup & Data Loading\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "import seaborn as sns\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('data.csv')  # Update path as needed\n",
    "print(\"Initial shape:\", df.shape)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2943f94",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 2. Preprocessing\n",
    "\n",
    "# Separate features (X) and labels (y)\n",
    "X = df.drop(columns=['class', 'ID'])  # All handwriting features\n",
    "y = df['class']  # Alzheimer's labels (if available)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Verify no negative values remain\n",
    "assert (X_scaled >= 0).all(), \"Negative values detected after scaling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ee4485",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 3. Dimensionality Reduction with PCA\n",
    "\n",
    "# Reduce to 2D for visualization\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Plot PCA results\n",
    "plt.figure(figsize=(10, 6))\n",
    "if y is not None:\n",
    "    sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=y, palette='viridis')\n",
    "else:\n",
    "    sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1])\n",
    "plt.title(\"PCA of Handwriting Features\")\n",
    "plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)\")\n",
    "plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5b4388",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 4. K-Means Clustering\n",
    "# Determine optimal cluster count (Elbow Method)\n",
    "inertias = []\n",
    "for k in range(1, 6):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_pca)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "plt.plot(range(1, 6), inertias, marker='o')\n",
    "plt.title(\"Elbow Method for Optimal K\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.show()\n",
    "\n",
    "# Run K-Means with selected K (2 for AD vs Control)\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "clusters = kmeans.fit_predict(X_pca)\n",
    "\n",
    "# Add clusters back to dataframe\n",
    "df['cluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6b8ad5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 5. Evaluation\n",
    "# If ground truth labels exist\n",
    "if y is not None:\n",
    "    print(\"Adjusted Rand Index:\", adjusted_rand_score(y, clusters))\n",
    "    \n",
    "# Silhouette Score (always works)\n",
    "print(\"Silhouette Score:\", silhouette_score(X_pca, clusters))\n",
    "\n",
    "# Visualize clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=clusters, palette='viridis')\n",
    "plt.title(\"K-Means Clustering Results\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a945350",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# 6. Interpret Clusters\n",
    "\n",
    "# Compare cluster means in original feature space\n",
    "cluster_means = pd.DataFrame(\n",
    "    scaler.inverse_transform(pca.inverse_transform(kmeans.cluster_centers_)),\n",
    "    columns=X.columns\n",
    ")\n",
    "\n",
    "print(\"Cluster Centers (Original Features):\")\n",
    "display(cluster_means)\n",
    "\n",
    "# Plot key feature distributions by cluster\n",
    "plt.figure(figsize=(15, 5))\n",
    "for i, feature in enumerate(['air_time1', 'pressure1', 'mean_speed1']):\n",
    "    plt.subplot(1, 3, i+1)\n",
    "    sns.boxplot(x='cluster', y=feature, data=df)\n",
    "    plt.title(f\"{feature} by Cluster\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977ba4af",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ## 7. Save Results\n",
    "\n",
    "df.to_csv('DARWIN_clustered.csv', index=False)\n",
    "print(\"Results saved to DARWIN_clustered.csv\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
